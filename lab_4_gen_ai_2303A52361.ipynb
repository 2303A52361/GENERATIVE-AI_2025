{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52361/GENERATIVE-AI_2025/blob/main/lab_4_gen_ai_2303A52361.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRS_4U7j7esm"
      },
      "source": [
        "Design a simple ANN architecture with one input and one output layer (no hidden layer). Assume a linear activation function in the output layer. • Write Python code for a backpropagation algorithm with gradient descent optimization to update weights and bias parameters of the ANN model with training data shown in Table 1. • Calculate the mean square error with training and testing data shown in Table 2. • Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the output with deployed ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "klPJB0gq7noc",
        "outputId": "bdd77ae0-b360-43a4-be2c-b66589bb0117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1 Prediction: 0.44071475334147203\n",
            "Test 2 Prediction: 0.5000957599286809\n"
          ]
        }
      ],
      "source": [
        "# Training data\n",
        "train_x = [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.3, 0.4, 0.5], [0.5, 0.6, 0.7], [0.1, 0.3, 0.5],\n",
        "           [0.2, 0.4, 0.6], [0.3, 0.5, 0.7], [0.4, 0.6, 0.8], [0.5, 0.7, 0.1]]\n",
        "train_y = [0.14, 0.20, 0.26, 0.38, 0.22, 0.28, 0.34, 0.40, 0.22]\n",
        "\n",
        "test_x = [[0.6, 0.7, 0.8], [0.7, 0.8, 0.9]]\n",
        "test_y = [0.44, 0.50]\n",
        "\n",
        "# Initialize\n",
        "weights = [0.1, 0.1, 0.1]\n",
        "bias = 0.0\n",
        "lr = 0.01\n",
        "\n",
        "# Train\n",
        "for _ in range(1000):\n",
        "    for i in range(len(train_x)):\n",
        "        pred = sum(train_x[i][j] * weights[j] for j in range(3)) + bias\n",
        "        error = pred - train_y[i]\n",
        "        for j in range(3):\n",
        "            weights[j] -= lr * error * train_x[i][j]\n",
        "        bias -= lr * error\n",
        "\n",
        "# Test\n",
        "for i in range(len(test_x)):\n",
        "    pred = sum(test_x[i][j] * weights[j] for j in range(3)) + bias\n",
        "    print(f\"Test {i+1} Prediction: {pred}\")\n",
        "\n",
        "# Predict\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "pred = sum([x1, x2, x3][j] * weights[j] for j in range(3)) + bias\n",
        "print(\"Your Prediction:\", pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6cCzuYy7sX4"
      },
      "source": [
        "Design a simple ANN architecture with one input and one output layer (no hidden layer). Assume a sigmoid activation function shown in the equation 1 in the output layer. f (x) = 1 1 + e−x (1) • Write Python code for a backpropagation algorithm with gradient descent optimization to update weights and bias parameters of the ANN model with training data shown in Table\n",
        "\n",
        "• Calculate the mean square error with training and testing data shown in Table 4. • Write Python code that reads the input data [x1, x2, and x3] from the user.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI5dJTy_7vXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a38dbe1-8290-453c-d8b1-49cbe8ac02c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1 Prediction: 0.603206203474566\n",
            "Test 2 Prediction: 0.6154334562628674\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "# Training data\n",
        "train_x = [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.3, 0.4, 0.5], [0.5, 0.6, 0.7], [0.1, 0.3, 0.5],\n",
        "           [0.2, 0.4, 0.6], [0.3, 0.5, 0.7], [0.4, 0.6, 0.8], [0.5, 0.7, 0.1]]\n",
        "train_y = [0.5349, 0.5498, 0.5646, 0.5939, 0.5548, 0.5695, 0.5842, 0.5987, 0.5548]\n",
        "\n",
        "test_x = [[0.6, 0.7, 0.8], [0.7, 0.8, 0.9]]\n",
        "test_y = [0.6083, 0.6225]\n",
        "\n",
        "# Initialize\n",
        "weights = [0.1, 0.1, 0.1]\n",
        "bias = 0.0\n",
        "lr = 0.01\n",
        "\n",
        "# Train\n",
        "for _ in range(1000):\n",
        "    for i in range(len(train_x)):\n",
        "        z = sum(train_x[i][j] * weights[j] for j in range(3)) + bias\n",
        "        pred = sigmoid(z)\n",
        "        error = pred - train_y[i]\n",
        "        for j in range(3):\n",
        "            weights[j] -= lr * error * train_x[i][j]\n",
        "        bias -= lr * error\n",
        "\n",
        "# Test\n",
        "for i in range(len(test_x)):\n",
        "    z = sum(test_x[i][j] * weights[j] for j in range(3)) + bias\n",
        "    pred = sigmoid(z)\n",
        "    print(f\"Test {i+1} Prediction: {pred}\")\n",
        "\n",
        "# Predict\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "z = sum([x1, x2, x3][j] * weights[j] for j in range(3)) + bias\n",
        "pred = sigmoid(z)\n",
        "print(\"Your Prediction:\", pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONHhiqE5ap/XK8usq/1mdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}